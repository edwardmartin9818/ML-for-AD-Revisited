{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e310d520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (18,19,20,102,103,104) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "b'Skipping line 2904: expected 38 fields, saw 73\\nSkipping line 3201: expected 38 fields, saw 72\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "base = \"C:\\\\Users\\\\edwar\\OneDrive\\Desktop\\Diss\\Data\\To use\\\\baseline\\\\\"\n",
    "files = [f for f in os.listdir(base) if os.path.isfile(os.path.join(base, f))]\n",
    "dfs = {f: pd.read_csv(base+f, error_bad_lines=False) for f in files}\n",
    "\n",
    "###### INITIAL SEARCH FOR VARIABLES BASED ON PAPER ######\n",
    "\n",
    "basic_fields = ['ID','PTID','RID','VISCODE','VISCODE2','Phase']\n",
    "\n",
    "#Create Dict where key = filename (-.csv) and the list = [var in file 1, var in file 2]\n",
    "f_dict = {'PTDEMOG': ['PTGENDER','AGE','PTMARRY','PTEDUCAT','PTETHCAT','PTRACCAT','BMI'], #Patient Demogs,\n",
    "         'DESIKANLAB': ['PHS','CIR'], #Desikan Lab Polygenic Hazard Score,\n",
    "         'FHQ': ['FHQMOM','FHQMOMAD','FHQDAD','FHQDADAD'],#Family History Questionnaire ,\n",
    "         'LABDATA': ['AXT117','BAT126','HMT10','CMT11' ,'HMT100','HMT102','HMT11','HMT12','HMT13','HMT15','HMT16','HMT17','HMT18','HMT19','HMT2','HMT3','HMT4','HMT40','HMT7','HMT8','HMT9','RCT1','RCT11','RCT12','RCT13','RCT14','RCT1407','RCT1408','RCT183','RCT19','RCT20','RCT29','RCT3','RCT5','RCT6','RCT9','RCT392','RCT4','RCT8'], # Laboratory data \n",
    "         'UPENNBIOMK9': ['ABETA','TAU','PTAU'],#UPENN CSF Biomarkers Elecsys \n",
    "         'ADNIMERGE':['APOE 4'],#Genetics (found in ADNIMERGE.csv)\n",
    "         'BLSCHECK': ['BCNAUSEA','BCVOMIT','BCDIARRH','BCCONSTP','BCABDOMN','BCSWEATN','BCDIZZY','BCENERGY','BCDROWSY','BCVISION'],#Patient Symptoms\n",
    "         'HAASS_WASHU_LAB': ['WU_STREM2','WU_STREM2_CV','WU_STREM2CORRECTED','MSD_STREM2','MSD_STREM2_CV','MSD_STREM2CORRECTED','MSD_PGRN','MSD_PGRN_CV','MSD_PGRNCORRECTED'],#Haass and Wash U lab summaries \n",
    "         'LOCLAB': ['CTWHITE','CTRED','PROTEIN','GLUCOSE'],#Local Lab Results\n",
    "         'MODHACH': ['HMSCORE','TOTAL SCORE'],#Modified Hachinski Ischemia Scale\n",
    "         'NEUROEXM': ['NXVISUAL','NXAUDITO','NXTREMOR','NXCONSCI','NXNERVE','NXMOTOR','NXFINGER','NXHEEL','NXSENSOR','NXTENDON','NXPLANTA','NXGAIT'],#Neurological Exam\n",
    "         'PHYSICAL': ['PXGENAPP','PXHEADEY','PXNECK','PXCHEST','PXHEART','PXABDOM','PXEXTREM','PXPERIPH','PXSKIN','PXMUSCUL'] #Physical Exam  \n",
    "         }\n",
    "\n",
    "#Dict of variables found as column name in corresponding CSV file\n",
    "#f_found = {\"CSV filename\" : Intersection of variables MEANT to be in df and what IS in df}\n",
    "f_found = {key: dfs[key+'.csv'].columns.intersection(f_dict[key]) for key in f_dict.keys()}\n",
    "#Dict of variables not found in corresponding CSV file\n",
    "#F_missing = {\"CSV filename\" : Difference between variables searched for as a set and found variables as a set, cast to a list}\n",
    "f_missing = {key: list(set(f_dict[key]).difference(set(f_found[key]))) for key in f_dict.keys()}\n",
    "\n",
    "###### INITIAL SEARCH FOR VARIABLES BASED ON PAPER ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "05442947",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### REVISED SEARCH #1 BASED ON FOUND/MISSING VARIABLES ######\n",
    "# Reference 'Data dict.csv' to find varibale locations\n",
    "\n",
    "##Changes:\n",
    "# 'PTDEMOG' : ['AGE' -> '', 'BMI' -> '']\n",
    "# ADNIMERGE : ['APOE 4' -> 'APOE4', '' -> 'AGE']\n",
    "# MODHACH : ['TOTAL SCORE' -> '']\n",
    "\n",
    "#APOE 4 renamed\n",
    "#AGE moved to ADNIMERGE\n",
    "#BMI not found anywhere, deleted\n",
    "#TOTAL SCORE = HMSCORE, so is duplicate variable and deleted\n",
    "\n",
    "#Create Dict where key = filename (-.csv) and the list = [var in file 1, var in file 2]\n",
    "f_dict = {'PTDEMOG': ['PTGENDER','PTMARRY','PTEDUCAT','PTETHCAT','PTRACCAT'], #Patient Demogs,\n",
    "         'DESIKANLAB': ['PHS','CIR'], #Desikan Lab Polygenic Hazard Score,\n",
    "         'FHQ': ['FHQMOM','FHQMOMAD','FHQDAD','FHQDADAD'],#Family History Questionnaire ,\n",
    "         'LABDATA': ['AXT117','BAT126','HMT10','CMT11' ,'HMT100','HMT102','HMT11','HMT12','HMT13','HMT15','HMT16','HMT17','HMT18','HMT19','HMT2','HMT3','HMT4','HMT40','HMT7','HMT8','HMT9','RCT1','RCT11','RCT12','RCT13','RCT14','RCT1407','RCT1408','RCT183','RCT19','RCT20','RCT29','RCT3','RCT5','RCT6','RCT9','RCT392','RCT4','RCT8'], # Laboratory data \n",
    "         'UPENNBIOMK9': ['ABETA','TAU','PTAU'],#UPENN CSF Biomarkers Elecsys \n",
    "         'ADNIMERGE':['APOE4', 'AGE'],#Genetics (found in ADNIMERGE.csv)\n",
    "         'BLSCHECK': ['BCNAUSEA','BCVOMIT','BCDIARRH','BCCONSTP','BCABDOMN','BCSWEATN','BCDIZZY','BCENERGY','BCDROWSY','BCVISION'],#Patient Symptoms\n",
    "         'HAASS_WASHU_LAB': ['WU_STREM2','WU_STREM2_CV','WU_STREM2CORRECTED','MSD_STREM2','MSD_STREM2_CV','MSD_STREM2CORRECTED','MSD_PGRN','MSD_PGRN_CV','MSD_PGRNCORRECTED'],#Haass and Wash U lab summaries \n",
    "         'LOCLAB': ['CTWHITE','CTRED','PROTEIN','GLUCOSE'],#Local Lab Results\n",
    "         'MODHACH': ['HMSCORE'],#Modified Hachinski Ischemia Scale\n",
    "         'NEUROEXM': ['NXVISUAL','NXAUDITO','NXTREMOR','NXCONSCI','NXNERVE','NXMOTOR','NXFINGER','NXHEEL','NXSENSOR','NXTENDON','NXPLANTA','NXGAIT'],#Neurological Exam\n",
    "         'PHYSICAL': ['PXGENAPP','PXHEADEY','PXNECK','PXCHEST','PXHEART','PXABDOM','PXEXTREM','PXPERIPH','PXSKIN','PXMUSCUL'] #Physical Exam  \n",
    "         }\n",
    "\n",
    "#Dict of variables found as column name in corresponding CSV file\n",
    "#f_found = {\"CSV filename\" : Intersection of variables MEANT to be in df and what IS in df}\n",
    "f_found = {key: dfs[key+'.csv'].columns.intersection(f_dict[key]) for key in f_dict.keys()}\n",
    "#Dict of variables not found in corresponding CSV file\n",
    "#F_missing = {\"CSV filename\" : Difference between variables searched for as a set and found variables as a set, cast to a list}\n",
    "f_missing = {key: list(set(f_dict[key]).difference(set(f_found[key]))) for key in f_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "eb35d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find variables in ADNIMERGE which have a direct baseline version\n",
    "#Variables found:\n",
    "#ABETA : ABETA_bl\n",
    "#TAU : TAU_bl\n",
    "#PTAU : PTAU_bl\n",
    "from itertools import chain\n",
    "\n",
    "f_temp = list(chain.from_iterable(f_dict.values())) #Create list of all variables to be found\n",
    "#Create dict of masks of column names in ADNIMERGE which contain a required variable as a substring (looking for _bl extensions)\n",
    "f_mask = {f: dfs['ADNIMERGE.csv'].columns.str.contains(f) for f in f_temp}\n",
    "#Fetch all variables indicated in mask dict above\n",
    "fields = [dfs['ADNIMERGE.csv'].columns[f_mask[key]].tolist() for key in f_mask.keys()]\n",
    "fields = [f for f in fields if f != []] #Remove empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e3bfe928",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find all variables in ADNIMERGE with '_bl' extension\n",
    "# May be useful later!!!!\n",
    "#Variables found:\n",
    "#Create mask of column names in ADNIMERGE which contain '_bl' extension\n",
    "f_mask = dfs['ADNIMERGE.csv'].columns.str.contains('_bl')\n",
    "#Fetch all variables indicated in mask above\n",
    "fields = dfs['ADNIMERGE.csv'].columns[f_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0ae003db",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### REVISED SEARCH #2 BASED ON FOUND/MISSING VARIABLES ######\n",
    "# Reference 'Data dict.csv' to find varibale locations\n",
    "\n",
    "##Changes:\n",
    "# UPENNBIOMK9 : ['ABETA' -> '','TAU' -> '','PTAU' -> ''] (DELETED)\n",
    "# ADNIMERGE : ['' -> 'ABETA_bl', '' -> 'TAU_bl', '' -> 'PTAU_bl']\n",
    "\n",
    "#Removed ABETA, TAU, PTAU from UPENNBIOMK9 and added _bl versions to ADNIMERGE\n",
    "#UPENNBIOMK9 now empty,so deleted\n",
    "\n",
    "#Create Dict where key = filename (-.csv) and the list = [var in file 1, var in file 2]\n",
    "f_dict = {'PTDEMOG': ['PTGENDER','PTMARRY','PTEDUCAT','PTETHCAT','PTRACCAT'], #Patient Demogs,\n",
    "         'DESIKANLAB': ['PHS','CIR'], #Desikan Lab Polygenic Hazard Score,\n",
    "         'FHQ': ['FHQMOM','FHQMOMAD','FHQDAD','FHQDADAD'],#Family History Questionnaire ,\n",
    "         'LABDATA': ['AXT117','BAT126','HMT10','CMT11' ,'HMT100','HMT102','HMT11','HMT12','HMT13','HMT15','HMT16','HMT17','HMT18','HMT19','HMT2','HMT3',\n",
    "                     'HMT4','HMT40','HMT7','HMT8','HMT9','RCT1','RCT11','RCT12','RCT13','RCT14','RCT1407','RCT1408','RCT183','RCT19','RCT20','RCT29','RCT3',\n",
    "                     'RCT5','RCT6','RCT9','RCT392','RCT4','RCT8'], # Laboratory data \n",
    "         'ADNIMERGE':['APOE4', 'AGE','ABETA_bl','TAU_bl','PTAU_bl'],#Genetics (found in ADNIMERGE.csv)\n",
    "         'BLSCHECK': ['BCNAUSEA','BCVOMIT','BCDIARRH','BCCONSTP','BCABDOMN','BCSWEATN','BCDIZZY','BCENERGY','BCDROWSY','BCVISION'],#Patient Symptoms\n",
    "         'HAASS_WASHU_LAB': ['WU_STREM2','WU_STREM2_CV','WU_STREM2CORRECTED','MSD_STREM2','MSD_STREM2_CV','MSD_STREM2CORRECTED','MSD_PGRN','MSD_PGRN_CV','MSD_PGRNCORRECTED'],#Haass and Wash U lab summaries \n",
    "         'LOCLAB': ['CTWHITE','CTRED','PROTEIN','GLUCOSE'],#Local Lab Results\n",
    "         'MODHACH': ['HMSCORE'],#Modified Hachinski Ischemia Scale\n",
    "         'NEUROEXM': ['NXVISUAL','NXAUDITO','NXTREMOR','NXCONSCI','NXNERVE','NXMOTOR','NXFINGER','NXHEEL','NXSENSOR','NXTENDON','NXPLANTA','NXGAIT'],#Neurological Exam\n",
    "         'PHYSICAL': ['PXGENAPP','PXHEADEY','PXNECK','PXCHEST','PXHEART','PXABDOM','PXEXTREM','PXPERIPH','PXSKIN','PXMUSCUL'] #Physical Exam  \n",
    "         }\n",
    "\n",
    "#Dict of variables found as column name in corresponding CSV file\n",
    "#f_found = {\"CSV filename\" : Intersection of variables MEANT to be in df and what IS in df}\n",
    "f_found = {key: dfs[key+'.csv'].columns.intersection(f_dict[key]) for key in f_dict.keys()}\n",
    "#Dict of variables not found in corresponding CSV file\n",
    "#F_missing = {\"CSV filename\" : Difference between variables searched for as a set and found variables as a set, cast to a list}\n",
    "f_missing = {key: list(set(f_dict[key]).difference(set(f_found[key]))) for key in f_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "a54b92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict of required columns for each df. Intersection of most common fields and fields found previously\n",
    "req_f_dict = {key: dfs[key+'.csv'].columns.intersection(f_dict[key]+basic_fields) for key in f_dict.keys()}\n",
    "#Dict of dfs reduced to only the fields required as specified in 'req_f_dict'\n",
    "dfs = {key: dfs[key+'.csv'][req_f_dict[key]] for key in req_f_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "9ef4ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to take a df and change it to contain only one VISCODE column, replacing \n",
    "#VISCODE if possible (VISCODE2 is what we want, VISCODE is useless)\n",
    "def mod_viscode(df):\n",
    "    if 'VISCODE2' in df.columns.tolist():\n",
    "        if 'VISCODE' in df.columns.tolist():\n",
    "            df = df.drop('VISCODE', axis='columns')\n",
    "            df = df.rename({'VISCODE2':'VISCODE'}, axis='columns')\n",
    "#     elif 'VISCODE' not in df.columns.tolist():\n",
    "#         df['VISCODE'] = 'bl'\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "dfa5e622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phase</th>\n",
       "      <th>ID</th>\n",
       "      <th>RID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>VISCODE2</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTMARRY</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTETHCAT</th>\n",
       "      <th>PTRACCAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>138900</td>\n",
       "      <td>6990</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>139219</td>\n",
       "      <td>6986</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>140102</td>\n",
       "      <td>6951</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>140375</td>\n",
       "      <td>6996</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>ADNI3</td>\n",
       "      <td>140456</td>\n",
       "      <td>6994</td>\n",
       "      <td>sc</td>\n",
       "      <td>sc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4723 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Phase      ID   RID VISCODE VISCODE2  PTGENDER  PTMARRY  PTEDUCAT  \\\n",
       "0     ADNI1      18     2      sc       sc       1.0      1.0      16.0   \n",
       "1     ADNI1      20     1       f        f       2.0      1.0      18.0   \n",
       "2     ADNI1      22     3      sc       sc       1.0      1.0      18.0   \n",
       "3     ADNI1      24     4      sc       sc       1.0      1.0      10.0   \n",
       "4     ADNI1      26     5      sc       sc       1.0      1.0      16.0   \n",
       "...     ...     ...   ...     ...      ...       ...      ...       ...   \n",
       "4718  ADNI3  138900  6990      sc       sc       2.0      4.0      16.0   \n",
       "4719  ADNI3  139219  6986      sc       sc       2.0      3.0      15.0   \n",
       "4720  ADNI3  140102  6951      sc       sc       1.0      3.0      13.0   \n",
       "4721  ADNI3  140375  6996      sc       sc       2.0      1.0      16.0   \n",
       "4722  ADNI3  140456  6994      sc       sc       2.0      1.0      18.0   \n",
       "\n",
       "      PTETHCAT  PTRACCAT  \n",
       "0          2.0       5.0  \n",
       "1         -4.0      -4.0  \n",
       "2          2.0       5.0  \n",
       "3          1.0       5.0  \n",
       "4          2.0       5.0  \n",
       "...        ...       ...  \n",
       "4718       2.0       4.0  \n",
       "4719       2.0       4.0  \n",
       "4720       2.0       4.0  \n",
       "4721       2.0       2.0  \n",
       "4722       2.0       4.0  \n",
       "\n",
       "[4723 rows x 10 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['PTDEMOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "482d242c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "4718    False\n",
       "4719    False\n",
       "4720    False\n",
       "4721    False\n",
       "4722    False\n",
       "Length: 4723, dtype: bool"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mod_viscode(dfs['PTDEMOG'])['VISCODE'] != dfs['PTDEMOG']['VISCODE2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "828b1e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc       3589\n",
       "f         564\n",
       "m60       185\n",
       "m12       130\n",
       "m72        87\n",
       "m48        72\n",
       "m24        21\n",
       "m36        13\n",
       "m18        13\n",
       "m06        10\n",
       "bl          9\n",
       "m30         8\n",
       "m66         5\n",
       "m78         4\n",
       "m84         4\n",
       "m90         2\n",
       "m54         1\n",
       "m03         1\n",
       "scmri       1\n",
       "m42         1\n",
       "Name: VISCODE, dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_viscode(dfs['PTDEMOG'])['VISCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7d4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4c7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
